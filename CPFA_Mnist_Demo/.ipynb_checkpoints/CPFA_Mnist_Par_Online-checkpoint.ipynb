{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA intial finish\n",
      "0 total 0.229692935944 seconds\n",
      "1 total 0.17803812027 seconds\n",
      "2 total 0.169187068939 seconds\n",
      "3 total 0.167852163315 seconds\n",
      "4 total 0.173209190369 seconds\n",
      "5 total 0.170871019363 seconds\n",
      "6 total 0.172657012939 seconds\n",
      "7 total 0.159860134125 seconds\n",
      "8 total 0.171437978745 seconds\n",
      "9 total 0.187035083771 seconds\n",
      "0 total 0.178347826004 seconds\n",
      "1 total 0.170581102371 seconds\n",
      "2 total 0.178069114685 seconds\n",
      "3 total 0.181601047516 seconds\n",
      "4 total 0.177217006683 seconds\n",
      "5 total 0.15655708313 seconds\n",
      "6 total 0.176469087601 seconds\n",
      "7 total 0.162996053696 seconds\n",
      "8 total 0.173371076584 seconds\n",
      "9 total 0.168344020844 seconds\n",
      "0 total 0.168977975845 seconds\n",
      "1 total 0.164035081863 seconds\n",
      "2 total 0.170154094696 seconds\n",
      "3 total 0.166532993317 seconds\n",
      "4 total 0.167381048203 seconds\n",
      "5 total 0.183008909225 seconds\n",
      "6 total 0.180354118347 seconds\n",
      "7 total 0.158377885818 seconds\n",
      "8 total 0.172966003418 seconds\n",
      "9 total 0.169445037842 seconds\n",
      "0 total 0.173925161362 seconds\n",
      "1 total 0.168633937836 seconds\n",
      "2 total 0.183315992355 seconds\n",
      "3 total 0.177638053894 seconds\n",
      "4 total 0.173660039902 seconds\n",
      "5 total 0.190088033676 seconds\n",
      "6 total 0.173815011978 seconds\n",
      "7 total 0.186089992523 seconds\n",
      "8 total 0.170167922974 seconds\n",
      "9 total 0.170585870743 seconds\n",
      "0 total 0.188470840454 seconds\n",
      "1 total 0.178411960602 seconds\n",
      "2 total 0.181689023972 seconds\n",
      "3 total 0.170464992523 seconds\n",
      "4 total 0.176690101624 seconds\n",
      "5 total 0.180308103561 seconds\n",
      "6 total 0.179000139236 seconds\n",
      "7 total 0.168020963669 seconds\n",
      "8 total 0.176970005035 seconds\n",
      "9 total 0.172370910645 seconds\n",
      "0 total 0.173950910568 seconds\n",
      "1 total 0.17019701004 seconds\n",
      "2 total 0.167054891586 seconds\n",
      "3 total 0.166501045227 seconds\n",
      "4 total 0.180964946747 seconds\n",
      "5 total 0.169123888016 seconds\n",
      "6 total 0.172611951828 seconds\n",
      "7 total 0.166485786438 seconds\n",
      "8 total 0.17941403389 seconds\n",
      "9 total 0.175759077072 seconds\n",
      "0 total 0.171250104904 seconds\n",
      "1 total 0.168294906616 seconds\n",
      "2 total 0.166551828384 seconds\n",
      "3 total 0.168190002441 seconds\n",
      "4 total 0.174728870392 seconds\n",
      "5 total 0.183243989944 seconds\n",
      "6 total 0.172093153 seconds\n",
      "7 total 0.185380935669 seconds\n",
      "8 total 0.169084072113 seconds\n",
      "9 total 0.17004609108 seconds\n",
      "0 total 0.172533988953 seconds\n",
      "1 total 0.166388034821 seconds\n",
      "2 total 0.16952586174 seconds\n",
      "3 total 0.170953989029 seconds\n",
      "4 total 0.171022891998 seconds\n",
      "5 total 0.165820837021 seconds\n",
      "6 total 0.168768882751 seconds\n",
      "7 total 0.167937994003 seconds\n",
      "8 total 0.169700860977 seconds\n",
      "9 total 0.173858880997 seconds\n",
      "0 total 0.180629968643 seconds\n",
      "1 total 0.162675142288 seconds\n",
      "2 total 0.16261100769 seconds\n",
      "3 total 0.173832893372 seconds\n",
      "4 total 0.165338993073 seconds\n",
      "5 total 0.169511079788 seconds\n",
      "6 total 0.170293092728 seconds\n",
      "7 total 0.166532993317 seconds\n",
      "8 total 0.176405906677 seconds\n",
      "9 total 0.165712833405 seconds\n",
      "0 total 0.172608137131 seconds\n",
      "1 total 0.167056798935 seconds\n",
      "2 total 0.158551931381 seconds\n",
      "3 total 0.174939870834 seconds\n",
      "4 total 0.173429012299 seconds\n",
      "5 total 0.158086061478 seconds\n",
      "6 total 0.179929018021 seconds\n",
      "7 total 0.174918174744 seconds\n",
      "8 total 0.18466091156 seconds\n",
      "9 total 0.187417030334 seconds\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jan 10 22:41:31 2018\n",
    "\n",
    "@author: wangchaojie\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "np.random.RandomState(1)\n",
    "\n",
    "real_min = 2.2e-10\n",
    "def log_max(x):\n",
    "    return np.log(np.maximum(x, real_min))\n",
    "\n",
    "def ProjSimplexSpecial(Phi_tmp, Phi_old, epsilon):\n",
    "    Phinew = Phi_tmp - (Phi_tmp.sum(0) - 1) * Phi_old\n",
    "    if  np.where(Phinew[:,:]<=0)[0].size >0:\n",
    "        Phinew = np.maximum(epsilon,Phinew)\n",
    "        Phinew = Phinew/np.maximum(real_min,Phinew.sum(0))\n",
    "    return Phinew\n",
    "\n",
    "#====================== Load data ======================#\n",
    "import scipy.io as sio\n",
    "data = sio.loadmat('./mnist_gray')\n",
    "train_data  = np.array(np.ceil(data['train_mnist'] * 25), order='C')[:, 0:100]  # 0-1    V*N\n",
    "\n",
    "X = np.transpose(np.transpose(train_data).reshape([train_data.shape[1], 1, 28, 28]), [3, 2, 1, 0])  # V*W*C*N\n",
    "[V1, V2, C, N_train] = X.shape\n",
    "\n",
    "#====================== Setting ======================#\n",
    "Setting = {}\n",
    "Setting['N_train'] = N_train\n",
    "Setting['K1']    = 16\n",
    "Setting['K1_V1'] = V1\n",
    "Setting['K1_V2'] = V2\n",
    "Setting['K1_K3'] = 28\n",
    "Setting['K1_K4'] = 3\n",
    "Setting['K1_K1'] = Setting['K1_V1'] + 1 - Setting['K1_K3']\n",
    "Setting['K1_K2'] = Setting['K1_V2'] + 1 - Setting['K1_K4']\n",
    "Setting['Iter']  = 200\n",
    "\n",
    "#====================== SuperParams ======================#\n",
    "SuperParams = {}\n",
    "SuperParams['gamma0'] = 0.1\n",
    "SuperParams['c0']     = 0.1  # r\n",
    "SuperParams['a0']     = 0.1\n",
    "SuperParams['b0']     = 0.1  # p\n",
    "SuperParams['e0']     = 0.1\n",
    "SuperParams['f0']     = 0.1\n",
    "SuperParams['eta']    = 0.05\n",
    "\n",
    "#====================== CUDA Initial ======================#\n",
    "import pycuda.curandom as curandom\n",
    "import pycuda.driver as drv\n",
    "import pycuda.tools\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "mod = SourceModule(\"\"\"\n",
    "\n",
    "#include <stdio.h>\n",
    "__global__ void Multi_Sampler(int* para, float *word_aug_stack, float *MultRate_stack, int *row_index, int *column_index, int *page_index, float *value_index, float *Params_W1_nk1, float *Params_D1_k1, float *Params_W1_nk1_Aug, float *Params_D1_k1_Aug)\n",
    "{\n",
    "    int K1         = para[0];\n",
    "    int K1_K1      = para[1];\n",
    "    int K1_K2      = para[2];\n",
    "    int K1_K3      = para[3];\n",
    "    int K1_K4      = para[4];\n",
    "    int word_total = para[5];\n",
    "\n",
    "    int ix = blockDim.x * blockIdx.x + threadIdx.x; \n",
    "    int iy = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "    unsigned int idx = iy* blockDim.x *gridDim.x+ ix;\n",
    "    \n",
    "    if ((idx < word_total))\n",
    "    {\n",
    "        int v1 = row_index[idx];                 // row_index\n",
    "        int v2 = column_index[idx];              // col_index\n",
    "        int n  = page_index[idx];                // file_index\n",
    "        float value = value_index[idx];\n",
    "        \n",
    "        int word_k1_min = 0;\n",
    "        int word_k1_max = 0;\n",
    "        int word_k2_min = 0;\n",
    "        int word_k2_max = 0;\n",
    "        \n",
    "        // word_k1\n",
    "        if ((v1 - K1_K3 + 1) > 0)\n",
    "            word_k1_min = v1 - K1_K3 + 1;\n",
    "        else\n",
    "            word_k1_min = 0;\n",
    "\n",
    "        if (v1 > K1_K1 -1)\n",
    "            word_k1_max = K1_K1 -1;\n",
    "        else\n",
    "            word_k1_max = v1;\n",
    "\n",
    "        int l_word_k1 = word_k1_max - word_k1_min + 1;\n",
    "        int *word_k1  = new int[l_word_k1];\n",
    "        for (int i = 0; i < (l_word_k1); i++)\n",
    "            word_k1[i] = word_k1_min + i;\n",
    "\n",
    "        // word_k2\n",
    "        if ((v2 - K1_K4 + 1) > 0)\n",
    "            word_k2_min = v2 - K1_K4 + 1;\n",
    "        else\n",
    "            word_k2_min = 0;\n",
    "\n",
    "        if (v2 > K1_K2 -1)\n",
    "            word_k2_max = K1_K2 -1;\n",
    "        else\n",
    "            word_k2_max = v2;\n",
    "\n",
    "        int l_word_k2 = word_k2_max - word_k2_min + 1;\n",
    "        int *word_k2  = new int[l_word_k2];\n",
    "        for (int i = 0; i < (l_word_k2); i++)\n",
    "            word_k2[i] = word_k2_min + i;\n",
    "\n",
    "        // word_k3\n",
    "        int *word_k3 = new int[l_word_k1];\n",
    "        for (int i = 0; i < (l_word_k1); i++)\n",
    "            word_k3[i] = v1 - word_k1[i] ;\n",
    "\n",
    "        // word_k4\n",
    "        int *word_k4 = new int[l_word_k2];\n",
    "        for (int i = 0; i < (l_word_k2); i++)\n",
    "            word_k4[i] = v2 - word_k2[i] ;\n",
    "        \n",
    "        float MultRate_sum = 0;\n",
    "        //word_aug_stack\n",
    "        //MultRate_stack\n",
    "        //Params_W1_nk1\n",
    "        //Params_D1_k1\n",
    "        int stack_start = idx * K1_K4 * K1;\n",
    "        \n",
    "        for (int i = 0; i < K1; i++)\n",
    "        {\n",
    "            for (int k = 0; k < (l_word_k1); k++)\n",
    "            {\n",
    "                for (int j = 0; j < (l_word_k2); j++)\n",
    "                {\n",
    "                    int temp_a = (n) * K1 * K1_K1 * K1_K2 + (i) * K1_K1 * K1_K2 + word_k1[k] * K1_K2 + (word_k2[j]);\n",
    "                    int temp_b = (i) * K1_K3 * K1_K4 + word_k3[k] * K1_K4 + (word_k4[j]);\n",
    "                    int temp_c = stack_start + i*l_word_k1*l_word_k2 + k*l_word_k2 + j;\n",
    "                    \n",
    "                    MultRate_stack[temp_c] = Params_W1_nk1[temp_a] * Params_D1_k1[temp_b];\n",
    "                    MultRate_sum = MultRate_sum + MultRate_stack[temp_c];\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for (int i = 0; i < K1; i++)\n",
    "        {\n",
    "            for (int k = 0; k < (l_word_k1); k++)\n",
    "            {\n",
    "                for (int j = 0; j < (l_word_k2); j++)\n",
    "                {\n",
    "                    int temp_a = (n) * K1 * K1_K1 * K1_K2 + (i) * K1_K1 * K1_K2 + word_k1[k] * K1_K2 + (word_k2[j]);\n",
    "                    int temp_b = (i) * K1_K3 * K1_K4 + word_k3[k] * K1_K4 + (word_k4[j]);\n",
    "                    int temp_c = stack_start + i*l_word_k1*l_word_k2 + k*l_word_k2 + j;\n",
    "                    \n",
    "                    if (MultRate_sum == 0)\n",
    "                    {\n",
    "                        MultRate_stack[temp_c] = 1.0 / (K1 * l_word_k1 * l_word_k2);\n",
    "                        word_aug_stack[temp_c] = MultRate_stack[temp_c] * value;\n",
    "                    }\n",
    "                    else\n",
    "                    {\n",
    "                        MultRate_stack[temp_c] = MultRate_stack[temp_c] / MultRate_sum;\n",
    "                        word_aug_stack[temp_c] = MultRate_stack[temp_c] * value;\n",
    "                    }\n",
    "\n",
    "                    atomicAdd(&Params_W1_nk1_Aug[temp_a], word_aug_stack[temp_c]);\n",
    "                    atomicAdd(&Params_D1_k1_Aug[temp_b], word_aug_stack[temp_c]);\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        delete[] word_k1;\n",
    "        delete[] word_k2;\n",
    "        delete[] word_k3;\n",
    "        delete[] word_k4; \n",
    "    }\n",
    "    \n",
    "}\n",
    " \"\"\")\n",
    "\n",
    "print \"CUDA intial finish\"\n",
    "\n",
    "#====================== Initial ======================#\n",
    "Params = {}\n",
    "Params['D1_k1'] = np.random.rand(Setting['K1'], Setting['K1_K3'], Setting['K1_K4'])\n",
    "for k1 in range(Setting['K1']):\n",
    "    Params['D1_k1'][k1, :, :] = Params['D1_k1'][k1, :, :] / np.sum(Params['D1_k1'][k1, :, :])\n",
    "    \n",
    "#====================== Online Setting ======================#         \n",
    "Setting['SweepTimes'] = 10\n",
    "Setting['Minibatch']  = 10\n",
    "Setting['Burnin']     = 24\n",
    "Setting['Collection'] = 16  \n",
    "Setting['Iterall']    = 500\n",
    "Setting['tao0FR']     = 0\n",
    "Setting['kappa0FR']   = 0.9\n",
    "Setting['tao0']       = 20\n",
    "Setting['kappa0']     = 0.7\n",
    "Setting['epsi0']      = 1\n",
    "Setting['FurCollapse']= 1  # 1 or 0\n",
    "Setting['flag']       = 0\n",
    "\n",
    "NDot     = [0]\n",
    "Xt_to_t1 = [0]\n",
    "WSZS     = [0]\n",
    "EWSZS    = [0]\n",
    "\n",
    "ForgetRate   = np.power((Setting['tao0FR'] + np.linspace(1, Setting['Iterall'], Setting['Iterall'])), -Setting['kappa0FR'])\n",
    "epsit        = np.power((Setting['tao0'] + np.linspace(1, Setting['Iterall'], Setting['Iterall'])), -Setting['kappa0'])\n",
    "epsit        = Setting['epsi0'] * epsit / epsit[0]\n",
    "update_count = 0\n",
    "\n",
    "#====================== SGMCMC ======================#\n",
    "from scipy.special import gamma\n",
    "import time\n",
    "for sweepi in range(Setting['SweepTimes']):\n",
    "    \n",
    "    train_index = np.random.permutation(np.arange(Setting['N_train']))          # 打乱\n",
    "    MBratio = np.floor(Setting['N_train'] / Setting['Minibatch']).astype('int') # 分minibatch\n",
    "    \n",
    "    for MBt in range(MBratio):\n",
    "\n",
    "        time_start = time.time()\n",
    "        \n",
    "        #====================== Gibbs ======================#\n",
    "        MBObserved = (sweepi * MBratio + MBt).astype('int')   \n",
    "        MB_index   = train_index[MBt * Setting['Minibatch'] + np.arange(Setting['Minibatch'])].astype('int')\n",
    "        \n",
    "        X_batch = X[:,:,:,MB_index]\n",
    "        [X_rows, X_cols, X_channel, X_file_index] = np.where(X_batch)\n",
    "        X_value = X[np.where(X)]\n",
    "        \n",
    "        X_rows       = np.array(X_rows, dtype = 'int32')\n",
    "        X_cols       = np.array(X_cols, dtype = 'int32')\n",
    "        X_file_index = np.array(X_file_index, dtype = 'int32')\n",
    "        X_value      = np.array(X_value, dtype = 'float32')\n",
    "\n",
    "        word_total     = len(X_rows)\n",
    "        word_aug_stack = np.zeros((Setting['K1']*Setting['K1_K4']*word_total),dtype=np.float32)\n",
    "        MultRate_stack = np.zeros((Setting['K1']*Setting['K1_K4']*word_total),dtype=np.float32)\n",
    "        Batch_Para     = np.array([Setting['K1'], Setting['K1_K1'], Setting['K1_K2'], Setting['K1_K3'], Setting['K1_K4'], word_total], dtype=np.int32)\n",
    "\n",
    "        Params['W1_nk1'] = np.random.rand(Setting['Minibatch'], Setting['K1'], Setting['K1_K1'], Setting['K1_K2'])\n",
    "        Params['p2_nk1'] = np.zeros([Setting['Minibatch'], Setting['K1']])\n",
    "        Params['c2_nk1'] = np.zeros([Setting['Minibatch'], Setting['K1']])\n",
    "        \n",
    "        block_x = 128\n",
    "        grid_x  = 128\n",
    "        grid_y  = word_total / (block_x * grid_x) + 1\n",
    "        \n",
    "        Params['D1_k1_Aug_Collection']  = np.zeros_like(Params['D1_k1'])\n",
    "        \n",
    "        for t in range(Setting['Burnin'] + Setting['Collection']):\n",
    "        \n",
    "            #====================== Augmentation ======================#\n",
    "            Params['D1_k1_Aug']  = np.zeros_like(Params['D1_k1'])\n",
    "            Params['W1_nk1_Aug'] = np.zeros_like(Params['W1_nk1'])     \n",
    "\n",
    "            W1_nk1     = np.array(Params['W1_nk1'], dtype = 'float32', order='C')\n",
    "            D1_k1      = np.array(Params['D1_k1'], dtype = 'float32', order='C')\n",
    "            W1_nk1_Aug = np.zeros(W1_nk1.shape, dtype = 'float32', order='C')\n",
    "            D1_k1_Aug  = np.zeros(D1_k1.shape,dtype = 'float32', order='C')\n",
    "\n",
    "            fuc = mod.get_function(\"Multi_Sampler\")\n",
    "            fuc(drv.In(Batch_Para), drv.In(word_aug_stack), drv.In(MultRate_stack), drv.In(X_rows), drv.In(X_cols), drv.In(X_file_index), drv.In(X_value), drv.In(W1_nk1), drv.In(D1_k1), drv.InOut(W1_nk1_Aug), drv.InOut(D1_k1_Aug), grid =(grid_x, grid_y, 1)  ,block=(block_x,1,1))   # 一般最多512个并行线程\n",
    "\n",
    "            Params['W1_nk1_Aug'] = np.round(W1_nk1_Aug)\n",
    "            if (t >= Setting['Burnin']):\n",
    "                Params['D1_k1_Aug_Collection'] = Params['D1_k1_Aug_Collection'] + D1_k1_Aug\n",
    "    \n",
    "            #====================== Local Parameters Update ======================#\n",
    "            for k1 in range(Setting['K1']):\n",
    "                # Multi\n",
    "                X_k1_n12 = np.reshape(Params['W1_nk1_Aug'][:, k1, :, :], [Setting['Minibatch'], Setting['K1_K1'] * Setting['K1_K2']])\n",
    "                X_k1_12n = np.transpose(X_k1_n12)\n",
    "\n",
    "                Params['p2_nk1'][:, k1] = np.random.beta(SuperParams['a0'] + np.sum(X_k1_n12, axis=1), 0.1 + SuperParams['b0'])\n",
    "                Params['c2_nk1'][:, k1] = (1 - Params['p2_nk1'][:, k1]) / Params['p2_nk1'][:, k1]\n",
    "\n",
    "                # Update 1th W\n",
    "                W_k1_sn = np.random.gamma(SuperParams['gamma0'] + X_k1_12n) / (1 + Params['c2_nk1'][:, k1])\n",
    "                Params['W1_nk1'][:, k1, :, :] = np.reshape(np.transpose(W_k1_sn), [Setting['Minibatch'], Setting['K1_K1'], Setting['K1_K2']])\n",
    "        \n",
    "        #====================== Global Parameters Update ======================#\n",
    "        Params['D1_k1_Aug'] = np.round(Params['D1_k1_Aug_Collection'] /  Setting['Collection'])\n",
    "        Phi   = np.transpose(np.reshape(Params['D1_k1'], [Setting['K1'], Setting['K1_K3'] * Setting['K1_K4']]))  \n",
    "        WSZS  = np.transpose(np.reshape(Params['D1_k1_Aug'], [Setting['K1'], Setting['K1_K3'] * Setting['K1_K4']]))  # V*K\n",
    "        EWSZS = MBratio * WSZS \n",
    "        \n",
    "        if (MBObserved == 0):\n",
    "            NDot = EWSZS.sum(0) #按第0维度加和\n",
    "        else:\n",
    "            NDot = (1 - ForgetRate[MBObserved]) * NDot + ForgetRate[MBObserved] * EWSZS.sum(0)  \n",
    "        \n",
    "        tmp  = EWSZS + SuperParams['eta']\n",
    "        tmp  = (1 / (NDot+real_min)) * (tmp - tmp.sum(0) * Phi)  \n",
    "        tmp1 = (2 / (NDot+real_min)) * Phi\n",
    "        tmp  = Phi + epsit[MBObserved] * tmp + np.sqrt(epsit[MBObserved] * tmp1) * np.random.randn(Phi.shape[0],Phi.shape[1])\n",
    "        Phi  = ProjSimplexSpecial(tmp, Phi, 0)\n",
    "        Params['D1_k1'] = np.reshape(np.transpose(Phi), [Setting['K1'], Setting['K1_K3'], Setting['K1_K4']])\n",
    "        \n",
    "        time_end = time.time() \n",
    "        print  MBt, 'total', time_end - time_start, 'seconds'  \n",
    "        update_count = update_count + 1\n",
    "        \n",
    "        if update_count == Setting['Iterall']:\n",
    "            break\n",
    "            \n",
    "print \"Training phase finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0112459659576 seconds\n",
      "1 0.00617504119873 seconds\n",
      "2 0.00338816642761 seconds\n",
      "3 0.00365614891052 seconds\n",
      "4 0.00368690490723 seconds\n",
      "5 0.00321793556213 seconds\n",
      "6 0.00374603271484 seconds\n",
      "7 0.00360298156738 seconds\n",
      "8 0.00358200073242 seconds\n",
      "9 0.00373721122742 seconds\n",
      "10 0.00347089767456 seconds\n",
      "11 0.00418496131897 seconds\n",
      "12 0.00354790687561 seconds\n",
      "13 0.00360202789307 seconds\n",
      "14 0.00359010696411 seconds\n",
      "15 0.00317597389221 seconds\n",
      "16 0.00395607948303 seconds\n",
      "17 0.0036780834198 seconds\n",
      "18 0.00324201583862 seconds\n",
      "19 0.00354695320129 seconds\n",
      "20 0.00365114212036 seconds\n",
      "21 0.00330114364624 seconds\n",
      "22 0.00325012207031 seconds\n",
      "23 0.00334811210632 seconds\n",
      "24 0.00309300422668 seconds\n",
      "25 0.00331687927246 seconds\n",
      "26 0.0034511089325 seconds\n",
      "27 0.00348091125488 seconds\n",
      "28 0.00319790840149 seconds\n",
      "29 0.00349187850952 seconds\n",
      "30 0.00353002548218 seconds\n",
      "31 0.00385499000549 seconds\n",
      "32 0.00343990325928 seconds\n",
      "33 0.00335311889648 seconds\n",
      "34 0.00355386734009 seconds\n",
      "35 0.00398206710815 seconds\n",
      "36 0.00366902351379 seconds\n",
      "37 0.00325894355774 seconds\n",
      "38 0.00339913368225 seconds\n",
      "39 0.00325489044189 seconds\n",
      "40 0.00453495979309 seconds\n",
      "41 0.00330710411072 seconds\n",
      "42 0.00318098068237 seconds\n",
      "43 0.00315499305725 seconds\n",
      "44 0.00325798988342 seconds\n",
      "45 0.00316905975342 seconds\n",
      "46 0.00318384170532 seconds\n",
      "47 0.00295495986938 seconds\n",
      "48 0.00322294235229 seconds\n",
      "49 0.00326299667358 seconds\n",
      "50 0.00310802459717 seconds\n",
      "51 0.00310683250427 seconds\n",
      "52 0.00315403938293 seconds\n",
      "53 0.00308012962341 seconds\n",
      "54 0.00292706489563 seconds\n",
      "55 0.00317096710205 seconds\n",
      "56 0.00308990478516 seconds\n",
      "57 0.00293612480164 seconds\n",
      "58 0.00320601463318 seconds\n",
      "59 0.00295686721802 seconds\n",
      "60 0.00292778015137 seconds\n",
      "61 0.00293707847595 seconds\n",
      "62 0.0032160282135 seconds\n",
      "63 0.0028440952301 seconds\n",
      "64 0.00305080413818 seconds\n",
      "65 0.00313806533813 seconds\n",
      "66 0.00282406806946 seconds\n",
      "67 0.00302505493164 seconds\n",
      "68 0.00322890281677 seconds\n",
      "69 0.00309300422668 seconds\n",
      "70 0.00296998023987 seconds\n",
      "71 0.00326681137085 seconds\n",
      "72 0.00310611724854 seconds\n",
      "73 0.0032811164856 seconds\n",
      "74 0.00306510925293 seconds\n",
      "75 0.00287103652954 seconds\n",
      "76 0.00534510612488 seconds\n",
      "77 0.00291919708252 seconds\n",
      "78 0.00300002098083 seconds\n",
      "79 0.00320506095886 seconds\n",
      "80 0.00303888320923 seconds\n",
      "81 0.00288891792297 seconds\n",
      "82 0.00318813323975 seconds\n",
      "83 0.00281310081482 seconds\n",
      "84 0.00300192832947 seconds\n",
      "85 0.0031750202179 seconds\n",
      "86 0.00308799743652 seconds\n",
      "87 0.00295090675354 seconds\n",
      "88 0.00282096862793 seconds\n",
      "89 0.00323104858398 seconds\n",
      "90 0.00283813476562 seconds\n",
      "91 0.00301218032837 seconds\n",
      "92 0.0029399394989 seconds\n",
      "93 0.00282597541809 seconds\n",
      "94 0.00276708602905 seconds\n",
      "95 0.0028510093689 seconds\n",
      "96 0.00302386283875 seconds\n",
      "97 0.00296211242676 seconds\n",
      "98 0.00277400016785 seconds\n",
      "99 0.00302910804749 seconds\n",
      "100 0.00288081169128 seconds\n",
      "101 0.0026969909668 seconds\n",
      "102 0.002760887146 seconds\n",
      "103 0.00286912918091 seconds\n",
      "104 0.00296783447266 seconds\n",
      "105 0.00291895866394 seconds\n",
      "106 0.00301003456116 seconds\n",
      "107 0.00309014320374 seconds\n",
      "108 0.00277400016785 seconds\n",
      "109 0.00286412239075 seconds\n",
      "110 0.00290107727051 seconds\n",
      "111 0.0028600692749 seconds\n",
      "112 0.00297784805298 seconds\n",
      "113 0.00705194473267 seconds\n",
      "114 0.00273108482361 seconds\n",
      "115 0.0029718875885 seconds\n",
      "116 0.00306296348572 seconds\n",
      "117 0.00271415710449 seconds\n",
      "118 0.00277400016785 seconds\n",
      "119 0.00289583206177 seconds\n",
      "120 0.00292706489563 seconds\n",
      "121 0.00282907485962 seconds\n",
      "122 0.00295805931091 seconds\n",
      "123 0.00293898582458 seconds\n",
      "124 0.00304198265076 seconds\n",
      "125 0.00281286239624 seconds\n",
      "126 0.00302505493164 seconds\n",
      "127 0.0028030872345 seconds\n",
      "128 0.00304412841797 seconds\n",
      "129 0.00319504737854 seconds\n",
      "130 0.00305914878845 seconds\n",
      "131 0.00327205657959 seconds\n",
      "132 0.00283002853394 seconds\n",
      "133 0.00294399261475 seconds\n",
      "134 0.00286412239075 seconds\n",
      "135 0.00297212600708 seconds\n",
      "136 0.00297999382019 seconds\n",
      "137 0.00334906578064 seconds\n",
      "138 0.00289011001587 seconds\n",
      "139 0.0027539730072 seconds\n",
      "140 0.00281810760498 seconds\n",
      "141 0.00266695022583 seconds\n",
      "142 0.00286078453064 seconds\n",
      "143 0.00294494628906 seconds\n",
      "144 0.00280213356018 seconds\n",
      "145 0.00272488594055 seconds\n",
      "146 0.00292992591858 seconds\n",
      "147 0.00277614593506 seconds\n",
      "148 0.00293183326721 seconds\n",
      "149 0.00319600105286 seconds\n",
      "150 0.00268983840942 seconds\n",
      "151 0.00293898582458 seconds\n",
      "152 0.0028669834137 seconds\n",
      "153 0.00307011604309 seconds\n",
      "154 0.00296211242676 seconds\n",
      "155 0.00270700454712 seconds\n",
      "156 0.00283908843994 seconds\n",
      "157 0.0030300617218 seconds\n",
      "158 0.00299310684204 seconds\n",
      "159 0.00288009643555 seconds\n",
      "160 0.00277590751648 seconds\n",
      "161 0.0028030872345 seconds\n",
      "162 0.00288891792297 seconds\n",
      "163 0.00293588638306 seconds\n",
      "164 0.00291895866394 seconds\n",
      "165 0.00284790992737 seconds\n",
      "166 0.00281095504761 seconds\n",
      "167 0.0028030872345 seconds\n",
      "168 0.00304102897644 seconds\n",
      "169 0.00273990631104 seconds\n",
      "170 0.00271701812744 seconds\n",
      "171 0.00295114517212 seconds\n",
      "172 0.00289297103882 seconds\n",
      "173 0.00288915634155 seconds\n",
      "174 0.00292110443115 seconds\n",
      "175 0.00299286842346 seconds\n",
      "176 0.00282907485962 seconds\n",
      "177 0.00279593467712 seconds\n",
      "178 0.00285792350769 seconds\n",
      "179 0.00314784049988 seconds\n",
      "180 0.00290679931641 seconds\n",
      "181 0.00285816192627 seconds\n",
      "182 0.00284099578857 seconds\n",
      "183 0.00321912765503 seconds\n",
      "184 0.00317597389221 seconds\n",
      "185 0.00303196907043 seconds\n",
      "186 0.00335788726807 seconds\n",
      "187 0.00341701507568 seconds\n",
      "188 0.00303101539612 seconds\n",
      "189 0.00327801704407 seconds\n",
      "190 0.00298094749451 seconds\n",
      "191 0.00312805175781 seconds\n",
      "192 0.00319004058838 seconds\n",
      "193 0.00301694869995 seconds\n",
      "194 0.0030529499054 seconds\n",
      "195 0.00297117233276 seconds\n",
      "196 0.00325202941895 seconds\n",
      "197 0.00319194793701 seconds\n",
      "198 0.00306105613708 seconds\n",
      "199 0.00293493270874 seconds\n",
      "200 0.00332498550415 seconds\n",
      "201 0.00294208526611 seconds\n",
      "202 0.00278401374817 seconds\n",
      "203 0.00317311286926 seconds\n",
      "204 0.0031418800354 seconds\n",
      "205 0.00312089920044 seconds\n",
      "206 0.00273990631104 seconds\n",
      "207 0.00328397750854 seconds\n",
      "208 0.00318717956543 seconds\n",
      "209 0.00288510322571 seconds\n",
      "210 0.00317883491516 seconds\n",
      "211 0.00312900543213 seconds\n",
      "212 0.00299191474915 seconds\n",
      "213 0.00321388244629 seconds\n",
      "214 0.00311183929443 seconds\n",
      "215 0.00313019752502 seconds\n",
      "216 0.00314903259277 seconds\n",
      "217 0.00314402580261 seconds\n",
      "218 0.00335097312927 seconds\n",
      "219 0.0031590461731 seconds\n",
      "220 0.0030210018158 seconds\n",
      "221 0.00326204299927 seconds\n",
      "222 0.00317597389221 seconds\n",
      "223 0.00289988517761 seconds\n",
      "224 0.00322318077087 seconds\n",
      "225 0.00308394432068 seconds\n",
      "226 0.00296497344971 seconds\n",
      "227 0.00302815437317 seconds\n",
      "228 0.00293183326721 seconds\n",
      "229 0.00307512283325 seconds\n",
      "230 0.00283813476562 seconds\n",
      "231 0.00312304496765 seconds\n",
      "232 0.00331211090088 seconds\n",
      "233 0.0028657913208 seconds\n",
      "234 0.00308299064636 seconds\n",
      "235 0.00308609008789 seconds\n",
      "236 0.003093957901 seconds\n",
      "237 0.00305199623108 seconds\n",
      "238 0.00318503379822 seconds\n",
      "239 0.00300693511963 seconds\n",
      "240 0.00273299217224 seconds\n",
      "241 0.00279903411865 seconds\n",
      "242 0.00277805328369 seconds\n",
      "243 0.00278306007385 seconds\n",
      "244 0.00275802612305 seconds\n",
      "245 0.00272393226624 seconds\n",
      "246 0.00269508361816 seconds\n",
      "247 0.00277018547058 seconds\n",
      "248 0.00272297859192 seconds\n",
      "249 0.0027232170105 seconds\n",
      "250 0.00283694267273 seconds\n",
      "251 0.00282192230225 seconds\n",
      "252 0.00283002853394 seconds\n",
      "253 0.002769947052 seconds\n",
      "254 0.00283098220825 seconds\n",
      "255 0.003084897995 seconds\n",
      "256 0.00311398506165 seconds\n",
      "257 0.00260710716248 seconds\n",
      "258 0.0028760433197 seconds\n",
      "259 0.00280499458313 seconds\n",
      "260 0.00295186042786 seconds\n",
      "261 0.00290203094482 seconds\n",
      "262 0.00279998779297 seconds\n",
      "263 0.00305700302124 seconds\n",
      "264 0.00269985198975 seconds\n",
      "265 0.00288200378418 seconds\n",
      "266 0.00285005569458 seconds\n",
      "267 0.00274395942688 seconds\n",
      "268 0.00313711166382 seconds\n",
      "269 0.00317001342773 seconds\n",
      "270 0.00284290313721 seconds\n",
      "271 0.00279784202576 seconds\n",
      "272 0.00326204299927 seconds\n",
      "273 0.00299000740051 seconds\n",
      "274 0.00309610366821 seconds\n",
      "275 0.002849817276 seconds\n",
      "276 0.0030620098114 seconds\n",
      "277 0.00281405448914 seconds\n",
      "278 0.00307178497314 seconds\n",
      "279 0.00331497192383 seconds\n",
      "280 0.00308394432068 seconds\n",
      "281 0.00291800498962 seconds\n",
      "282 0.00314688682556 seconds\n",
      "283 0.00307607650757 seconds\n",
      "284 0.00294804573059 seconds\n",
      "285 0.00283098220825 seconds\n",
      "286 0.00318789482117 seconds\n",
      "287 0.00322890281677 seconds\n",
      "288 0.00286793708801 seconds\n",
      "289 0.00269317626953 seconds\n",
      "290 0.00317811965942 seconds\n",
      "291 0.00323510169983 seconds\n",
      "292 0.00288319587708 seconds\n",
      "293 0.00315809249878 seconds\n",
      "294 0.00345206260681 seconds\n",
      "295 0.00302195549011 seconds\n",
      "296 0.00271797180176 seconds\n",
      "297 0.00327110290527 seconds\n",
      "298 0.00318002700806 seconds\n",
      "299 0.00301885604858 seconds\n",
      "300 0.00305485725403 seconds\n",
      "301 0.00323677062988 seconds\n",
      "302 0.0030460357666 seconds\n",
      "303 0.00295400619507 seconds\n",
      "304 0.00324296951294 seconds\n",
      "305 0.00307202339172 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 0.00295996665955 seconds\n",
      "307 0.00293588638306 seconds\n",
      "308 0.00299000740051 seconds\n",
      "309 0.0030460357666 seconds\n",
      "310 0.00307703018188 seconds\n",
      "311 0.00346112251282 seconds\n",
      "312 0.00293207168579 seconds\n",
      "313 0.00299096107483 seconds\n",
      "314 0.00324606895447 seconds\n",
      "315 0.00310206413269 seconds\n",
      "316 0.00283408164978 seconds\n",
      "317 0.00287103652954 seconds\n",
      "318 0.00312781333923 seconds\n",
      "319 0.00308799743652 seconds\n",
      "320 0.00308203697205 seconds\n",
      "321 0.00298619270325 seconds\n",
      "322 0.00317883491516 seconds\n",
      "323 0.00305199623108 seconds\n",
      "324 0.00274205207825 seconds\n",
      "325 0.00308203697205 seconds\n",
      "326 0.00294399261475 seconds\n",
      "327 0.00299096107483 seconds\n",
      "328 0.00290989875793 seconds\n",
      "329 0.00293397903442 seconds\n",
      "330 0.00265192985535 seconds\n",
      "331 0.00302195549011 seconds\n",
      "332 0.00299787521362 seconds\n",
      "333 0.00289487838745 seconds\n",
      "334 0.00300693511963 seconds\n",
      "335 0.00278091430664 seconds\n",
      "336 0.00296998023987 seconds\n",
      "337 0.0030779838562 seconds\n",
      "338 0.00293898582458 seconds\n",
      "339 0.00287795066833 seconds\n",
      "340 0.00308609008789 seconds\n",
      "341 0.00313210487366 seconds\n",
      "342 0.00292611122131 seconds\n",
      "343 0.00282001495361 seconds\n",
      "344 0.00312900543213 seconds\n",
      "345 0.00296878814697 seconds\n",
      "346 0.00285887718201 seconds\n",
      "347 0.00313377380371 seconds\n",
      "348 0.00288987159729 seconds\n",
      "349 0.00312614440918 seconds\n",
      "350 0.00284290313721 seconds\n",
      "351 0.00338387489319 seconds\n",
      "352 0.00327301025391 seconds\n",
      "353 0.00304102897644 seconds\n",
      "354 0.00309586524963 seconds\n",
      "355 0.00313305854797 seconds\n",
      "356 0.00327301025391 seconds\n",
      "357 0.00301194190979 seconds\n",
      "358 0.00329804420471 seconds\n",
      "359 0.00311398506165 seconds\n",
      "360 0.00287318229675 seconds\n",
      "361 0.00281286239624 seconds\n",
      "362 0.0031909942627 seconds\n",
      "363 0.00299000740051 seconds\n",
      "364 0.00282192230225 seconds\n",
      "365 0.00307679176331 seconds\n",
      "366 0.00313401222229 seconds\n",
      "367 0.00290584564209 seconds\n",
      "368 0.00331592559814 seconds\n",
      "369 0.0030369758606 seconds\n",
      "370 0.00291919708252 seconds\n",
      "371 0.00295400619507 seconds\n",
      "372 0.00318908691406 seconds\n",
      "373 0.00310897827148 seconds\n",
      "374 0.00281715393066 seconds\n",
      "375 0.00329995155334 seconds\n",
      "376 0.00303602218628 seconds\n",
      "377 0.00302791595459 seconds\n",
      "378 0.00296783447266 seconds\n",
      "379 0.00287508964539 seconds\n",
      "380 0.00286889076233 seconds\n",
      "381 0.00290083885193 seconds\n",
      "382 0.00282979011536 seconds\n",
      "383 0.00271487236023 seconds\n",
      "384 0.00290203094482 seconds\n",
      "385 0.00304484367371 seconds\n",
      "386 0.00275111198425 seconds\n",
      "387 0.00295615196228 seconds\n",
      "388 0.00281310081482 seconds\n",
      "389 0.00275301933289 seconds\n",
      "390 0.00290298461914 seconds\n",
      "391 0.00291991233826 seconds\n",
      "392 0.00296187400818 seconds\n",
      "393 0.00313401222229 seconds\n",
      "394 0.00279593467712 seconds\n",
      "395 0.00330400466919 seconds\n",
      "396 0.00317001342773 seconds\n",
      "397 0.00286388397217 seconds\n",
      "398 0.00330996513367 seconds\n",
      "399 0.00310015678406 seconds\n",
      "400 0.00299596786499 seconds\n",
      "401 0.0031750202179 seconds\n",
      "402 0.00292992591858 seconds\n",
      "403 0.00318312644958 seconds\n",
      "404 0.00284814834595 seconds\n",
      "405 0.00307893753052 seconds\n",
      "406 0.00300312042236 seconds\n",
      "407 0.00289297103882 seconds\n",
      "408 0.00291800498962 seconds\n",
      "409 0.00323009490967 seconds\n",
      "410 0.00299906730652 seconds\n",
      "411 0.0028510093689 seconds\n",
      "412 0.00300192832947 seconds\n",
      "413 0.00346088409424 seconds\n",
      "414 0.00294995307922 seconds\n",
      "415 0.00312805175781 seconds\n",
      "416 0.00320792198181 seconds\n",
      "417 0.00300598144531 seconds\n",
      "418 0.00308012962341 seconds\n",
      "419 0.0029559135437 seconds\n",
      "420 0.0031430721283 seconds\n",
      "421 0.00288009643555 seconds\n",
      "422 0.00282502174377 seconds\n",
      "423 0.00312900543213 seconds\n",
      "424 0.00305891036987 seconds\n",
      "425 0.00303792953491 seconds\n",
      "426 0.00294089317322 seconds\n",
      "427 0.00316786766052 seconds\n",
      "428 0.0029079914093 seconds\n",
      "429 0.00275993347168 seconds\n",
      "430 0.0029981136322 seconds\n",
      "431 0.00306606292725 seconds\n",
      "432 0.00283193588257 seconds\n",
      "433 0.00318503379822 seconds\n",
      "434 0.00275301933289 seconds\n",
      "435 0.00292301177979 seconds\n",
      "436 0.00284504890442 seconds\n",
      "437 0.00279498100281 seconds\n",
      "438 0.00310611724854 seconds\n",
      "439 0.00326490402222 seconds\n",
      "440 0.00281095504761 seconds\n",
      "441 0.00277996063232 seconds\n",
      "442 0.002934217453 seconds\n",
      "443 0.00305509567261 seconds\n",
      "444 0.00282502174377 seconds\n",
      "445 0.00309491157532 seconds\n",
      "446 0.00313997268677 seconds\n",
      "447 0.00292301177979 seconds\n",
      "448 0.00302791595459 seconds\n",
      "449 0.00321388244629 seconds\n",
      "450 0.0032651424408 seconds\n",
      "451 0.0030689239502 seconds\n",
      "452 0.00279688835144 seconds\n",
      "453 0.00298118591309 seconds\n",
      "454 0.003005027771 seconds\n",
      "455 0.00298500061035 seconds\n",
      "456 0.00321984291077 seconds\n",
      "457 0.00289988517761 seconds\n",
      "458 0.00288915634155 seconds\n",
      "459 0.00309801101685 seconds\n",
      "460 0.00305485725403 seconds\n",
      "461 0.00305199623108 seconds\n",
      "462 0.00279498100281 seconds\n",
      "463 0.00304794311523 seconds\n",
      "464 0.0032320022583 seconds\n",
      "465 0.00312781333923 seconds\n",
      "466 0.00281095504761 seconds\n",
      "467 0.0032000541687 seconds\n",
      "468 0.00322508811951 seconds\n",
      "469 0.0029091835022 seconds\n",
      "470 0.00292205810547 seconds\n",
      "471 0.00310397148132 seconds\n",
      "472 0.00319600105286 seconds\n",
      "473 0.00286483764648 seconds\n",
      "474 0.00342583656311 seconds\n",
      "475 0.00329899787903 seconds\n",
      "476 0.00295186042786 seconds\n",
      "477 0.00296211242676 seconds\n",
      "478 0.00311684608459 seconds\n",
      "479 0.00309991836548 seconds\n",
      "480 0.00287890434265 seconds\n",
      "481 0.00290584564209 seconds\n",
      "482 0.0031750202179 seconds\n",
      "483 0.00307011604309 seconds\n",
      "484 0.00289177894592 seconds\n",
      "485 0.00284004211426 seconds\n",
      "486 0.00304102897644 seconds\n",
      "487 0.00289797782898 seconds\n",
      "488 0.00295376777649 seconds\n",
      "489 0.00283789634705 seconds\n",
      "490 0.00276899337769 seconds\n",
      "491 0.002769947052 seconds\n",
      "492 0.00297808647156 seconds\n",
      "493 0.00277805328369 seconds\n",
      "494 0.00278496742249 seconds\n",
      "495 0.00285291671753 seconds\n",
      "496 0.00284004211426 seconds\n",
      "497 0.0029559135437 seconds\n",
      "498 0.00284004211426 seconds\n",
      "499 0.00277400016785 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#====================== Load data ======================#\n",
    "test_data   = np.array(np.ceil(data['train_mnist']*25), order = 'C')[:, 0:10]   #0-1    V*N\n",
    "\n",
    "X_test = np.transpose(np.transpose(test_data).reshape([test_data.shape[1], 1, 28, 28]), [3, 2, 1, 0])  # V*W*C*N\n",
    "[V1, V2, C, N_test] = X_test.shape\n",
    "[X_rows, X_cols, X_channel, X_file_index] = np.where(X_test)\n",
    "X_value = X_test[np.where(X_test)]\n",
    "\n",
    "#====================== Setting ======================#\n",
    "Setting['N_test'] = N_test\n",
    "Setting['Iter']   = 500\n",
    "\n",
    "#====================== Initial ======================#\n",
    "Params['W1_nk1']  = np.random.rand(Setting['N_test'], Setting['K1'], Setting['K1_K1'], Setting['K1_K2'])\n",
    "Params['p2_nk1']  = np.zeros([Setting['N_test'], Setting['K1']])\n",
    "Params['c2_nk1']  = np.zeros([Setting['N_test'], Setting['K1']])\n",
    "\n",
    "X_rows = np.array(X_rows, dtype = 'int32')\n",
    "X_cols = np.array(X_cols, dtype = 'int32')\n",
    "X_file_index = np.array(X_file_index, dtype = 'int32')\n",
    "X_value  = np.array(X_value, dtype = 'float32')\n",
    "\n",
    "word_total = len(X_rows)\n",
    "word_aug_stack = np.zeros((Setting['K1']*Setting['K1_K4']*word_total),dtype=np.float32)\n",
    "MultRate_stack = np.zeros((Setting['K1']*Setting['K1_K4']*word_total),dtype=np.float32)\n",
    "Batch_Para = np.array([Setting['K1'], Setting['K1_K1'], Setting['K1_K2'], Setting['K1_K3'], Setting['K1_K4'], word_total], dtype=np.int32)\n",
    "\n",
    "block_x = 128\n",
    "grid_x  = 128\n",
    "grid_y  = word_total / (block_x * grid_x) + 1\n",
    "\n",
    "for t in range(Setting['Iter']):\n",
    "    \n",
    "    #====================== Augmentation ======================#\n",
    "    time_start = time.time()\n",
    "    Params['D1_k1_Aug'] = np.zeros_like(Params['D1_k1'])\n",
    "    Params['W1_nk1_Aug'] = np.zeros_like(Params['W1_nk1'])\n",
    "\n",
    "    W1_nk1     = np.array(Params['W1_nk1'], dtype = 'float32', order='C')\n",
    "    D1_k1      = np.array(Params['D1_k1'], dtype = 'float32', order='C')\n",
    "    W1_nk1_Aug = np.zeros(W1_nk1.shape, dtype = 'float32', order='C')\n",
    "    D1_k1_Aug  = np.zeros(D1_k1.shape,dtype = 'float32', order='C')\n",
    "\n",
    "    \n",
    "    fuc = mod.get_function(\"Multi_Sampler\")\n",
    "    fuc(drv.In(Batch_Para), drv.In(word_aug_stack), drv.In(MultRate_stack), drv.In(X_rows), drv.In(X_cols), drv.In(X_file_index), drv.In(X_value), drv.In(W1_nk1), drv.In(D1_k1), drv.InOut(W1_nk1_Aug), drv.InOut(D1_k1_Aug), grid =(grid_x, grid_y, 1)  ,block=(block_x,1,1))   # 一般最多512个并行线程\n",
    "    time_end = time.time() \n",
    "    print t, time_end - time_start, 'seconds'\n",
    "    \n",
    "    Params['W1_nk1_Aug'] = np.round(W1_nk1_Aug)\n",
    "    Params['D1_k1_Aug'] = np.round(D1_k1_Aug)\n",
    "    \n",
    "    #====================== Local Parameters Update ======================#\n",
    "    for k1 in range(Setting['K1']):\n",
    "        # Multi\n",
    "        X_k1_n12 = np.reshape(Params['W1_nk1_Aug'][:, k1, :, :], [Setting['N_test'], Setting['K1_K1'] * Setting['K1_K2']])\n",
    "        X_k1_12n = np.transpose(X_k1_n12)\n",
    "\n",
    "        Params['p2_nk1'][:, k1] = np.random.beta(SuperParams['a0'] + np.sum(X_k1_n12, axis=1), 0.1 + SuperParams['b0'])\n",
    "        Params['c2_nk1'][:, k1] = (1 - Params['p2_nk1'][:, k1]) / Params['p2_nk1'][:, k1]\n",
    "\n",
    "        # Update 1th W\n",
    "        W_k1_sn = np.random.gamma(SuperParams['gamma0'] + X_k1_12n) / (1 + Params['c2_nk1'][:, k1])\n",
    "        Params['W1_nk1'][:, k1, :, :] = np.reshape(np.transpose(W_k1_sn), [Setting['N_test'], Setting['K1_K1'], Setting['K1_K2']])\n",
    "\n",
    "#====================== Reconstruct ======================#        \n",
    "def Conv_Aug(Kernel, Score_Shape):\n",
    "    [K1, K2] = Score_Shape\n",
    "    [K3, K4] = Kernel.shape\n",
    "    V1 = K1 + K3 - 1\n",
    "    V2 = K2 + K4 - 1\n",
    "\n",
    "    ## Padding\n",
    "    Kernel_Pad = np.zeros([2 * V1 - K3, 2 * V2 - K4])  ## Pad [V1 - K3, V2 - K4]\n",
    "    Kernel_Pad[V1 - K3: V1, V2 - K4: V2] = Kernel\n",
    "    Kernel_Pad = Kernel_Pad.T\n",
    "    M, N = Kernel_Pad.shape\n",
    "    # Parameters\n",
    "    col_extent = N - K1 + 1\n",
    "    row_extent = M - K2 + 1\n",
    "\n",
    "    # Get Starting block indices\n",
    "    start_idx = np.arange(K2)[:, None] * N + np.arange(K1)\n",
    "    # Get offsetted indices across the height and width of input array\n",
    "    offset_idx = np.arange(row_extent)[:, None] * N + np.arange(col_extent)\n",
    "    # Get all actual indices & index into input array for final output\n",
    "    out = np.take(Kernel_Pad, start_idx.ravel()[:, None] + offset_idx.ravel())\n",
    "    return np.flip(out.T, axis=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "test_index = 2\n",
    "X_test = np.zeros([28, 28])\n",
    "X_test[X_rows[np.where(X_file_index == test_index)], X_cols[np.where(X_file_index == test_index)]] = X_value[np.where(X_file_index == test_index)]\n",
    "plt.figure\n",
    "plt.imshow(X_test)\n",
    "plt.show()\n",
    "\n",
    "## 1th layer K - Augment\n",
    "X_nvk_params = np.zeros([Setting['N_test'], Setting['K1_V1'] * Setting['K1_V2'], Setting['K1']], order='C')\n",
    "for k in range(Setting['K1']):\n",
    "    D_k1 = Params['D1_k1'][k, :, :] / Params['D1_k1'][k, :, :].sum()\n",
    "    D_k1_Aug = Conv_Aug(D_k1, np.array([Setting['K1_K1'], Setting['K1_K2']]))\n",
    "    W_k1_ns = np.reshape(np.transpose(Params['W1_nk1'][:, k, :, :], [0, 2, 1]),[Setting['N_test'], Setting['K1_K1'] * Setting['K1_K2']])\n",
    "    X_nvk_params[:, :, k] = np.dot(D_k1_Aug, W_k1_ns.T).T\n",
    "Re_X = np.sum(X_nvk_params, 2).T\n",
    "\n",
    "plt.figure\n",
    "plt.imshow(np.transpose(Re_X[:, test_index].reshape([28, 28])))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
